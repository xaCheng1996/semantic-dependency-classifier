# 依存关系分类模型

本模型提供了一个基于神经网络实现实体间关系判断的算法，以达到语义理解的目标。模型输入是一个含有实体对的句子，以及对应实体的实体类型、位置等信息，模型输出该实体对之间是否存在修饰关系。

语义理解是自然语言处理中的重要问题，其中一个子问题就是判断一句话中不同词语、特别是重要命名实体之间的修饰关系。传统的方法为使用parser进行分析，得到整句话的树状结构；我们的模型则是基于神经网络，对经过标注的命名实体两两搭配，通过实体本身的信息和其在句中的语义信息判断它们之间是否存在修饰关系。模型结构如下图所示：

![模型结构](model.png)

entity为NER识别为实体的两个词，w为第i个词的word embedding，h为Bi-LSTM网络在第i个位置上的隐状态，t为实体对应类别的向量表示，pos为实体相对位置的向量表示；output为0或1，0代表无修饰关系。
h为语义信息，w和t为实体信息，pos为位置信息；我们对同一类信息进行拼接，然后使用了attention机制以解决不同语境下可能会侧重不同信息的问题。

## 运行环境

* Python 3.6
* Numpy
* Tensorflow 1.4.0

（兼容cpu & gpu）

## 快速上手

### 获取代码及数据

下载[源代码](https://github.com/zmtkeke/IRN)及自行构造的数据集（数据集为高度敏感数据，故只给出数据格式样例）到同一文件夹下

### 训练

在命令行中运行train.py进行训练:
```
python3 train.py
```

每个训练周期，程序将给出这段时间内训练集的损失函数值以及准确率、混淆矩阵，并保存最新的模型（保留5个最新的模型），如下所示：
> Validation:

> 2018-07-26T10:36:07.989370: step 75, loss 0.708905, acc 0.803333

> confusion matrix:

> [[351 136]

> [159 854]]

> Test:

> 2018-07-26T10:36:08.546653: step 75, loss 0.772554, acc 0.77125

> confusion matrix:

> [[ 105  175]

> [ 191 1129]]

> Saved model checkpoint to runs/char_with_attention/checkpoints/model-75

表示训练到第75个batch时，训练集上准确率是0.709，验证集上准确率为0.772，混淆矩阵如输出所示；当前保存在./checkpoint下的最新模型是第75个batch时的模型，用于继续训练或测试。


### 测试

####在命令行中测试分类器性能:

```python3 eval.py``` 
将对/checkpoints下指定的的模型进行测试，并输出结果至文件



## 细节

### 命令参数：选项(=[默认值]):
--BATCH_SIZE=64              batch size 大小   
--DROPOUT_KEEP_PROB=0.5      dropout 大小   
--EMBEDDING_DIM=300          word embedding 维数       
--L2_REG_LAMBDA=0.0          l2正则化参数   
--N_HIDDEN_STATE=128         Bi-LSTM中的隐状态个数   
--POS_EMBEDDING_DIM=100      pos embedding 维数   


### 评价指标
模型评价指标有两个，分别为实体对级准确率和整句级准确率。训练和测试过程中的准确率均为实体对级别的准确率，整句级需对结果输出文件经过后处理得到。


### 参考性能
在约14万条数据的规模下，训练值收敛约需要40分钟（Titan Xp），测试集准确率实体对级别87%，句子级准确率71%。


## 开源协议

BSD
